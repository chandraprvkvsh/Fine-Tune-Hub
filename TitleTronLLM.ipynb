{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**TitleTronLLM: From abstracts to elegant titles**"
      ],
      "metadata": {
        "id": "ACE9xzmohonz"
      },
      "id": "ACE9xzmohonz"
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Title Generator for Research Papers**\n",
        "\n",
        " This will take as input an abstract of your research paper and generate an apt title based on it. Mistral-7B, An open-source LLM is fined tuned on a dataset consisting of research paper abstracts and their titles which is extracted by me using NASA-ADS API for this purpose."
      ],
      "metadata": {
        "id": "D1ZXxoTaGYMA"
      },
      "id": "D1ZXxoTaGYMA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**The aim of this notebook is merely to fine-tune Mistral 7B model, In order to later use it for inference.**"
      ],
      "metadata": {
        "id": "YoTDs032GbQv"
      },
      "id": "YoTDs032GbQv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f03278a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-13T15:55:45.510528Z",
          "iopub.status.busy": "2024-03-13T15:55:45.510151Z",
          "iopub.status.idle": "2024-03-13T15:57:02.963544Z",
          "shell.execute_reply": "2024-03-13T15:57:02.962468Z"
        },
        "id": "2f03278a",
        "papermill": {
          "duration": 77.465761,
          "end_time": "2024-03-13T15:57:02.965985",
          "exception": false,
          "start_time": "2024-03-13T15:55:45.500224",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Making sure dependencies work in the desired way\n",
        "\n",
        "%%capture\n",
        "%pip install -U bitsandbytes\n",
        "%pip install -U transformers\n",
        "%pip install -U peft\n",
        "%pip install -U accelerate\n",
        "%pip install -U trl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2c10560",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-13T15:57:02.983988Z",
          "iopub.status.busy": "2024-03-13T15:57:02.983686Z",
          "iopub.status.idle": "2024-03-13T15:57:17.677780Z",
          "shell.execute_reply": "2024-03-13T15:57:17.676449Z"
        },
        "papermill": {
          "duration": 14.705604,
          "end_time": "2024-03-13T15:57:17.680210",
          "exception": false,
          "start_time": "2024-03-13T15:57:02.974606",
          "status": "completed"
        },
        "tags": [],
        "id": "a2c10560",
        "outputId": "001470c3-eafe-4e14-c08f-9bdd213bac2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting datasets==2.16.0\r\n",
            "  Downloading datasets-2.16.0-py3-none-any.whl.metadata (20 kB)\r\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (3.13.1)\r\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (1.26.4)\r\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (11.0.0)\r\n",
            "Collecting pyarrow-hotfix (from datasets==2.16.0)\r\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\r\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets==2.16.0)\r\n",
            "  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\r\n",
            "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (2.1.4)\r\n",
            "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (2.31.0)\r\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (4.66.1)\r\n",
            "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (3.4.1)\r\n",
            "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (0.70.16)\r\n",
            "Collecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.16.0)\r\n",
            "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\r\n",
            "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (3.9.1)\r\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (0.20.3)\r\n",
            "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (21.3)\r\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (6.0.1)\r\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.0) (23.2.0)\r\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.0) (6.0.4)\r\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.0) (1.9.3)\r\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.0) (1.4.1)\r\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.0) (1.3.1)\r\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.0) (4.0.3)\r\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets==2.16.0) (4.9.0)\r\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets==2.16.0) (3.1.1)\r\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.16.0) (3.3.2)\r\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.16.0) (3.6)\r\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.16.0) (1.26.18)\r\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.16.0) (2024.2.2)\r\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\r\n",
            "Collecting multiprocess (from datasets==2.16.0)\r\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl.metadata (7.2 kB)\r\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.16.0) (2.8.2)\r\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.16.0) (2023.3.post1)\r\n",
            "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.16.0) (2023.4)\r\n",
            "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.16.0) (1.16.0)\r\n",
            "Downloading datasets-2.16.0-py3-none-any.whl (507 kB)\r\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hDownloading dill-0.3.7-py3-none-any.whl (115 kB)\r\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\r\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hDownloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\r\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\r\n",
            "Installing collected packages: pyarrow-hotfix, fsspec, dill, multiprocess, datasets\r\n",
            "  Attempting uninstall: fsspec\r\n",
            "    Found existing installation: fsspec 2024.2.0\r\n",
            "    Uninstalling fsspec-2024.2.0:\r\n",
            "      Successfully uninstalled fsspec-2024.2.0\r\n",
            "  Attempting uninstall: dill\r\n",
            "    Found existing installation: dill 0.3.8\r\n",
            "    Uninstalling dill-0.3.8:\r\n",
            "      Successfully uninstalled dill-0.3.8\r\n",
            "  Attempting uninstall: multiprocess\r\n",
            "    Found existing installation: multiprocess 0.70.16\r\n",
            "    Uninstalling multiprocess-0.70.16:\r\n",
            "      Successfully uninstalled multiprocess-0.70.16\r\n",
            "  Attempting uninstall: datasets\r\n",
            "    Found existing installation: datasets 2.1.0\r\n",
            "    Uninstalling datasets-2.1.0:\r\n",
            "      Successfully uninstalled datasets-2.1.0\r\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
            "cudf 23.8.0 requires cubinlinker, which is not installed.\r\n",
            "cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
            "cudf 23.8.0 requires ptxcompiler, which is not installed.\r\n",
            "cuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
            "dask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
            "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\r\n",
            "apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\r\n",
            "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\r\n",
            "cudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.3.0 which is incompatible.\r\n",
            "cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\r\n",
            "cudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\r\n",
            "cuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\r\n",
            "dask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\r\n",
            "dask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\r\n",
            "dask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\r\n",
            "dask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\r\n",
            "distributed 2023.7.1 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\r\n",
            "gcsfs 2023.12.2.post1 requires fsspec==2023.12.2, but you have fsspec 2023.10.0 which is incompatible.\r\n",
            "pathos 0.3.2 requires dill>=0.3.8, but you have dill 0.3.7 which is incompatible.\r\n",
            "pathos 0.3.2 requires multiprocess>=0.70.16, but you have multiprocess 0.70.15 which is incompatible.\r\n",
            "raft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\r\n",
            "s3fs 2024.2.0 requires fsspec==2024.2.0, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
            "\u001b[0mSuccessfully installed datasets-2.16.0 dill-0.3.7 fsspec-2023.10.0 multiprocess-0.70.15 pyarrow-hotfix-0.6\r\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install datasets==2.16.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "589a277b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-13T15:57:17.702721Z",
          "iopub.status.busy": "2024-03-13T15:57:17.702391Z",
          "iopub.status.idle": "2024-03-13T15:57:38.918333Z",
          "shell.execute_reply": "2024-03-13T15:57:38.917519Z"
        },
        "id": "589a277b",
        "papermill": {
          "duration": 21.22985,
          "end_time": "2024-03-13T15:57:38.920693",
          "exception": false,
          "start_time": "2024-03-13T15:57:17.690843",
          "status": "completed"
        },
        "tags": [],
        "outputId": "bffa718e-dc4f-4db1-817f-fb9e2e00b1bb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-13 15:57:25.953894: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-13 15:57:25.954015: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-13 15:57:26.104299: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig,HfArgumentParser,TrainingArguments,pipeline, logging\n",
        "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
        "import os,torch, wandb\n",
        "from datasets import load_dataset\n",
        "from trl import SFTTrainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99c30a56",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-13T15:57:38.943434Z",
          "iopub.status.busy": "2024-03-13T15:57:38.942825Z",
          "iopub.status.idle": "2024-03-13T15:57:39.380062Z",
          "shell.execute_reply": "2024-03-13T15:57:39.379155Z"
        },
        "papermill": {
          "duration": 0.451113,
          "end_time": "2024-03-13T15:57:39.382650",
          "exception": false,
          "start_time": "2024-03-13T15:57:38.931537",
          "status": "completed"
        },
        "tags": [],
        "id": "99c30a56"
      },
      "outputs": [],
      "source": [
        "from kaggle_secrets import UserSecretsClient\n",
        "user_secrets = UserSecretsClient()\n",
        "secret_hf = user_secrets.get_secret(\"huggingface\")\n",
        "secret_wandb = user_secrets.get_secret(\"weightsandbiases\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "895397d0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-13T15:57:39.410643Z",
          "iopub.status.busy": "2024-03-13T15:57:39.410259Z",
          "iopub.status.idle": "2024-03-13T15:57:39.417933Z",
          "shell.execute_reply": "2024-03-13T15:57:39.416938Z"
        },
        "id": "895397d0",
        "outputId": "07b4bb79-e35e-43a9-c0a9-fabbb4ac2721",
        "papermill": {
          "duration": 0.02326,
          "end_time": "2024-03-13T15:57:39.420134",
          "exception": false,
          "start_time": "2024-03-13T15:57:39.396874",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'!huggingface-cli login --token $secret_hf'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# For enabling the huggingface functionality\n",
        "\n",
        "!huggingface-cli login --token $secret_hf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98896e3d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-13T15:57:39.446692Z",
          "iopub.status.busy": "2024-03-13T15:57:39.446362Z",
          "iopub.status.idle": "2024-03-13T15:58:11.358955Z",
          "shell.execute_reply": "2024-03-13T15:58:11.357890Z"
        },
        "id": "98896e3d",
        "papermill": {
          "duration": 31.931022,
          "end_time": "2024-03-13T15:58:11.364589",
          "exception": false,
          "start_time": "2024-03-13T15:57:39.433567",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Monitering the training with Weights and Biases\n",
        "\n",
        "wandb.login(key = secret_wandb)\n",
        "run = wandb.init(\n",
        "    project='mistral7b',\n",
        "    job_type=\"training\",\n",
        "    anonymous=\"allow\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07737abd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-13T15:58:11.391500Z",
          "iopub.status.busy": "2024-03-13T15:58:11.391184Z",
          "iopub.status.idle": "2024-03-13T15:58:11.395539Z",
          "shell.execute_reply": "2024-03-13T15:58:11.394689Z"
        },
        "papermill": {
          "duration": 0.018535,
          "end_time": "2024-03-13T15:58:11.397440",
          "exception": false,
          "start_time": "2024-03-13T15:58:11.378905",
          "status": "completed"
        },
        "tags": [],
        "id": "07737abd"
      },
      "outputs": [],
      "source": [
        "# Model directories\n",
        "\n",
        "base_model = \"/kaggle/input/mistral/pytorch/7b-v0.1-hf/1\"\n",
        "new_model = \"mistral_7b_finetuned\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e77f521",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-13T15:58:11.421644Z",
          "iopub.status.busy": "2024-03-13T15:58:11.420980Z",
          "iopub.status.idle": "2024-03-13T15:58:14.383099Z",
          "shell.execute_reply": "2024-03-13T15:58:14.381936Z"
        },
        "papermill": {
          "duration": 2.977087,
          "end_time": "2024-03-13T15:58:14.385795",
          "exception": false,
          "start_time": "2024-03-13T15:58:11.408708",
          "status": "completed"
        },
        "tags": [],
        "id": "2e77f521"
      },
      "outputs": [],
      "source": [
        "# Loading the dataset\n",
        "\n",
        "import pandas as pd\n",
        "df=pd.read_csv('/kaggle/input/ads-top70k/ADS-top70K.csv',usecols = ['abstract', 'title'])\n",
        "\n",
        "# For this notebook we are limiting the samples to 13000 but will fine-tune on full dataset too later\n",
        "\n",
        "df.drop_duplicates(inplace = True)\n",
        "df.dropna(inplace  = True)\n",
        "df=df.head(13000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e85a2fc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-13T15:58:14.468334Z",
          "iopub.status.busy": "2024-03-13T15:58:14.467289Z",
          "iopub.status.idle": "2024-03-13T15:58:14.473651Z",
          "shell.execute_reply": "2024-03-13T15:58:14.472541Z"
        },
        "papermill": {
          "duration": 0.023204,
          "end_time": "2024-03-13T15:58:14.475866",
          "exception": false,
          "start_time": "2024-03-13T15:58:14.452662",
          "status": "completed"
        },
        "tags": [],
        "id": "5e85a2fc"
      },
      "outputs": [],
      "source": [
        "# Getting the dataset in desired format\n",
        "\n",
        "def formatting_prompts_func(example):\n",
        "    output_texts = []\n",
        "    for i in range(df.shape[0]):\n",
        "        text = f\"<s>[INST] Craft an intelligent, clear, insightful, and succinct one-line title for the research paper, drawing inspiration from the abstract provided. \\n {example.iloc[i,0]} [/INST] {example.iloc[i,1]} </s>\"\n",
        "        output_texts.append(text)\n",
        "    return output_texts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2c7b5df",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-13T15:58:14.503793Z",
          "iopub.status.busy": "2024-03-13T15:58:14.503464Z",
          "iopub.status.idle": "2024-03-13T15:58:15.472014Z",
          "shell.execute_reply": "2024-03-13T15:58:15.470943Z"
        },
        "papermill": {
          "duration": 0.985679,
          "end_time": "2024-03-13T15:58:15.474709",
          "exception": false,
          "start_time": "2024-03-13T15:58:14.489030",
          "status": "completed"
        },
        "tags": [],
        "id": "d2c7b5df"
      },
      "outputs": [],
      "source": [
        "# Applying the above function on our dataframe\n",
        "\n",
        "dataset = formatting_prompts_func(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14b8b0a2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-13T15:58:15.504310Z",
          "iopub.status.busy": "2024-03-13T15:58:15.503328Z",
          "iopub.status.idle": "2024-03-13T15:58:15.511127Z",
          "shell.execute_reply": "2024-03-13T15:58:15.509926Z"
        },
        "papermill": {
          "duration": 0.025247,
          "end_time": "2024-03-13T15:58:15.513499",
          "exception": false,
          "start_time": "2024-03-13T15:58:15.488252",
          "status": "completed"
        },
        "tags": [],
        "id": "14b8b0a2",
        "outputId": "3427fe2b-39ff-4a4f-9f31-13077e4f88c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'<s>[INST] Craft an intelligent, clear, insightful, and succinct one-line title for the research paper, drawing inspiration from the abstract provided. \\n we present yolo, a new approach to object detection. prior work on object detection repurposes classifiers to perform detection. instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. a single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance. our unified architecture is extremely fast. our base yolo model processes images in real-time at 45 frames per second. a smaller version of the network, fast yolo, processes an astounding 155 frames per second while still achieving double the map of other real-time detectors. compared to state-of-the-art detection systems, yolo makes more localization errors but is far less likely to predict false detections where nothing exists. finally, yolo learns very general representations of objects. it outperforms all other detection methods, including dpm and r-cnn, by a wide margin when generalizing from natural images to artwork on both the picasso dataset and the people-art dataset. [/INST] you only look once: unified, real-time object detection </s>'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# A sample from dataset\n",
        "\n",
        "dataset[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1260c278",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-13T15:58:15.570969Z",
          "iopub.status.busy": "2024-03-13T15:58:15.570437Z",
          "iopub.status.idle": "2024-03-13T15:58:15.578325Z",
          "shell.execute_reply": "2024-03-13T15:58:15.577266Z"
        },
        "id": "1260c278",
        "papermill": {
          "duration": 0.025115,
          "end_time": "2024-03-13T15:58:15.580614",
          "exception": false,
          "start_time": "2024-03-13T15:58:15.555499",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Defining the 4 Bit Quantization configuration\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit= True,\n",
        "    bnb_4bit_quant_type= \"nf4\",\n",
        "    bnb_4bit_compute_dtype= torch.bfloat16,\n",
        "    bnb_4bit_use_double_quant= False,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18fb79d8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-13T15:58:15.609537Z",
          "iopub.status.busy": "2024-03-13T15:58:15.609084Z",
          "iopub.status.idle": "2024-03-13T16:01:26.848753Z",
          "shell.execute_reply": "2024-03-13T16:01:26.847820Z"
        },
        "papermill": {
          "duration": 191.256489,
          "end_time": "2024-03-13T16:01:26.850960",
          "exception": false,
          "start_time": "2024-03-13T15:58:15.594471",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "fca2f061a3524f14af34c4b511f7257d"
          ]
        },
        "id": "18fb79d8",
        "outputId": "3eb1d6d1-b671-4787-8564-c994646e1886"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fca2f061a3524f14af34c4b511f7257d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        }
      ],
      "source": [
        "# Loading the quantized model in memory\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "        base_model,\n",
        "        quantization_config=bnb_config,\n",
        "        torch_dtype=torch.bfloat16,\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=True,\n",
        ")\n",
        "\n",
        "model.config.use_cache = False\n",
        "model.config.pretraining_tp = 1\n",
        "model.gradient_checkpointing_enable()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db688889",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-13T16:01:26.899634Z",
          "iopub.status.busy": "2024-03-13T16:01:26.899286Z",
          "iopub.status.idle": "2024-03-13T16:01:27.021189Z",
          "shell.execute_reply": "2024-03-13T16:01:27.020256Z"
        },
        "papermill": {
          "duration": 0.136645,
          "end_time": "2024-03-13T16:01:27.023193",
          "exception": false,
          "start_time": "2024-03-13T16:01:26.886548",
          "status": "completed"
        },
        "tags": [],
        "id": "db688889",
        "outputId": "cf3935cd-c33b-4324-b39b-d8df6effa948"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(True, True)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Loading the tokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
        "tokenizer.padding_side = 'right'\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.add_eos_token = True\n",
        "tokenizer.add_bos_token, tokenizer.add_eos_token\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e74c625",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-13T16:01:27.048528Z",
          "iopub.status.busy": "2024-03-13T16:01:27.048180Z",
          "iopub.status.idle": "2024-03-13T16:01:27.052896Z",
          "shell.execute_reply": "2024-03-13T16:01:27.052052Z"
        },
        "papermill": {
          "duration": 0.01962,
          "end_time": "2024-03-13T16:01:27.054739",
          "exception": false,
          "start_time": "2024-03-13T16:01:27.035119",
          "status": "completed"
        },
        "tags": [],
        "id": "7e74c625"
      },
      "outputs": [],
      "source": [
        "# Setting the LoRA configuration\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=64,\n",
        "    lora_dropout=0.1,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88cae5f9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-13T16:01:27.079963Z",
          "iopub.status.busy": "2024-03-13T16:01:27.079263Z",
          "iopub.status.idle": "2024-03-13T16:01:27.227644Z",
          "shell.execute_reply": "2024-03-13T16:01:27.226874Z"
        },
        "id": "88cae5f9",
        "papermill": {
          "duration": 0.163372,
          "end_time": "2024-03-13T16:01:27.229899",
          "exception": false,
          "start_time": "2024-03-13T16:01:27.066527",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Attach LoRa Adapters in the Layers\n",
        "\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "peft_config = LoraConfig(\n",
        "    lora_config\n",
        ")\n",
        "model = get_peft_model(model, peft_config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dedb18e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-13T16:01:27.278963Z",
          "iopub.status.busy": "2024-03-13T16:01:27.278604Z",
          "iopub.status.idle": "2024-03-13T16:01:27.286912Z",
          "shell.execute_reply": "2024-03-13T16:01:27.286185Z"
        },
        "id": "9dedb18e",
        "papermill": {
          "duration": 0.023101,
          "end_time": "2024-03-13T16:01:27.288759",
          "exception": false,
          "start_time": "2024-03-13T16:01:27.265658",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Defining the training arguments\n",
        "\n",
        "training_arguments = TrainingArguments(\n",
        "    output_dir=new_model,\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=3,\n",
        "    logging_steps=10,\n",
        "    optim=\"paged_adamw_32bit\",\n",
        "    learning_rate=2e-4,\n",
        "    weight_decay=0.001,\n",
        "    fp16=False,\n",
        "    bf16=False,\n",
        "    max_grad_norm=0.3,\n",
        "    warmup_ratio=0.03,\n",
        "    group_by_length=True,\n",
        "    lr_scheduler_type=\"constant\",\n",
        "    gradient_checkpointing_kwargs={'use_reentrant':True},\n",
        "    report_to=\"wandb\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "164cf210",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-13T16:01:27.313617Z",
          "iopub.status.busy": "2024-03-13T16:01:27.313298Z",
          "iopub.status.idle": "2024-03-13T16:01:27.443267Z",
          "shell.execute_reply": "2024-03-13T16:01:27.442413Z"
        },
        "papermill": {
          "duration": 0.144928,
          "end_time": "2024-03-13T16:01:27.445592",
          "exception": false,
          "start_time": "2024-03-13T16:01:27.300664",
          "status": "completed"
        },
        "tags": [],
        "id": "164cf210"
      },
      "outputs": [],
      "source": [
        "# Getting the dataset to be compatible with Mistral\n",
        "\n",
        "from datasets import Dataset\n",
        "dataset2 = Dataset.from_dict({\"text\": dataset})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "289e3028",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-13T16:01:27.471035Z",
          "iopub.status.busy": "2024-03-13T16:01:27.470725Z",
          "iopub.status.idle": "2024-03-13T16:01:27.514892Z",
          "shell.execute_reply": "2024-03-13T16:01:27.514043Z"
        },
        "papermill": {
          "duration": 0.059021,
          "end_time": "2024-03-13T16:01:27.516956",
          "exception": false,
          "start_time": "2024-03-13T16:01:27.457935",
          "status": "completed"
        },
        "tags": [],
        "id": "289e3028",
        "outputId": "13b2f877-2ffe-494b-ec45-04969575c71b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'<s>[INST] Craft an intelligent, clear, insightful, and succinct one-line title for the research paper, drawing inspiration from the abstract provided. \\n we present yolo, a new approach to object detection. prior work on object detection repurposes classifiers to perform detection. instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. a single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance. our unified architecture is extremely fast. our base yolo model processes images in real-time at 45 frames per second. a smaller version of the network, fast yolo, processes an astounding 155 frames per second while still achieving double the map of other real-time detectors. compared to state-of-the-art detection systems, yolo makes more localization errors but is far less likely to predict false detections where nothing exists. finally, yolo learns very general representations of objects. it outperforms all other detection methods, including dpm and r-cnn, by a wide margin when generalizing from natural images to artwork on both the picasso dataset and the people-art dataset. [/INST] you only look once: unified, real-time object detection </s>'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# A sample from transformed dataset\n",
        "\n",
        "dataset2[\"text\"][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfb962b3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-13T16:01:27.542438Z",
          "iopub.status.busy": "2024-03-13T16:01:27.542148Z",
          "iopub.status.idle": "2024-03-13T16:01:34.077911Z",
          "shell.execute_reply": "2024-03-13T16:01:34.076982Z"
        },
        "papermill": {
          "duration": 6.551078,
          "end_time": "2024-03-13T16:01:34.080177",
          "exception": false,
          "start_time": "2024-03-13T16:01:27.529099",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "d4783fd18f4e49448a318a6c50e387ad"
          ]
        },
        "id": "dfb962b3",
        "outputId": "d6bc967f-7c95-4e56-facd-d45ac47e56dd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:225: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4783fd18f4e49448a318a6c50e387ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/13000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Setting SFT Trainer parameters\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset2,\n",
        "    peft_config=peft_config,\n",
        "    max_seq_length= None,\n",
        "    dataset_text_field=\"text\",\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        "    packing= False,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a757bc86",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-13T16:01:34.106471Z",
          "iopub.status.busy": "2024-03-13T16:01:34.106157Z",
          "iopub.status.idle": "2024-03-14T00:38:04.738537Z",
          "shell.execute_reply": "2024-03-14T00:38:04.737561Z"
        },
        "papermill": {
          "duration": 30990.659367,
          "end_time": "2024-03-14T00:38:04.752327",
          "exception": false,
          "start_time": "2024-03-13T16:01:34.092960",
          "status": "completed"
        },
        "tags": [],
        "id": "a757bc86",
        "outputId": "775741dc-a81c-4ba2-e4d4-079ec689b01e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1083' max='1083' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1083/1083 8:35:17, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.963800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.931600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.867100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.852600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.741200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.728200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.778400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.787400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.820000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.774700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>1.712700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.801400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>1.825900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>1.796500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.790600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>1.741000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>1.782600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>1.770300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>1.820000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.733600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>1.687400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>1.795400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>1.782600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>1.784700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.719100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>1.691200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>1.836500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>1.790800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>1.755900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.707600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>1.630400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>1.794200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>1.745400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>1.736000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>1.718400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>1.688800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>1.751400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>1.754300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>1.720000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.688100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>1.694700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>1.719800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>1.745600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>1.772300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>1.674600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>1.674300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>1.710300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>1.730000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>1.727400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.654600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>1.649000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>1.713800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>1.744200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>1.737500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>1.638100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>1.689300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>1.756900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>1.739400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>590</td>\n",
              "      <td>1.759800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.665000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>610</td>\n",
              "      <td>1.683600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>1.725100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>630</td>\n",
              "      <td>1.696600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>1.733500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>1.625900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>1.699300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>670</td>\n",
              "      <td>1.726000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>1.720100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>690</td>\n",
              "      <td>1.788200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>1.659400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>710</td>\n",
              "      <td>1.654800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>1.678500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>730</td>\n",
              "      <td>1.747700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>1.727700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>1.638000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>1.669100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>770</td>\n",
              "      <td>1.708700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>1.715700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>790</td>\n",
              "      <td>1.718500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>1.651200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>810</td>\n",
              "      <td>1.629900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>1.724300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>830</td>\n",
              "      <td>1.719500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>1.720000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>1.612700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>1.668500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>870</td>\n",
              "      <td>1.704400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>1.737800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>890</td>\n",
              "      <td>1.696100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>1.654300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>910</td>\n",
              "      <td>1.707900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>1.719100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>1.743000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>1.741900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>1.631200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>1.664200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>970</td>\n",
              "      <td>1.716300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>980</td>\n",
              "      <td>1.725300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>990</td>\n",
              "      <td>1.702000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.652200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1010</td>\n",
              "      <td>1.648600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1020</td>\n",
              "      <td>1.723500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1030</td>\n",
              "      <td>1.708200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1040</td>\n",
              "      <td>1.723900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>1.651500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1060</td>\n",
              "      <td>1.691100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1070</td>\n",
              "      <td>1.751500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1080</td>\n",
              "      <td>1.698400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /kaggle/input/mistral/pytorch/7b-v0.1-hf/1 - will assume that the vocabulary was not modified.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /kaggle/input/mistral/pytorch/7b-v0.1-hf/1 - will assume that the vocabulary was not modified.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1083, training_loss=1.7261364871665272, metrics={'train_runtime': 30983.6961, 'train_samples_per_second': 0.42, 'train_steps_per_second': 0.035, 'total_flos': 2.016554844460155e+17, 'train_loss': 1.7261364871665272, 'epoch': 1.0})"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c2f7e9d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-14T00:38:04.781679Z",
          "iopub.status.busy": "2024-03-14T00:38:04.780878Z",
          "iopub.status.idle": "2024-03-14T00:38:04.801222Z",
          "shell.execute_reply": "2024-03-14T00:38:04.800283Z"
        },
        "id": "6c2f7e9d",
        "papermill": {
          "duration": 0.037203,
          "end_time": "2024-03-14T00:38:04.803131",
          "exception": false,
          "start_time": "2024-03-14T00:38:04.765928",
          "status": "completed"
        },
        "tags": [],
        "outputId": "9d51f0dd-ae77-4fa6-f51c-c4f2ff9dee23"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PeftModel(\n",
              "  (base_model): LoraModel(\n",
              "    (model): MistralForCausalLM(\n",
              "      (model): MistralModel(\n",
              "        (embed_tokens): Embedding(32000, 4096)\n",
              "        (layers): ModuleList(\n",
              "          (0-31): 32 x MistralDecoderLayer(\n",
              "            (self_attn): MistralSdpaAttention(\n",
              "              (q_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "              (v_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "              (rotary_emb): MistralRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): MistralMLP(\n",
              "              (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "              (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "              (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): MistralRMSNorm()\n",
              "            (post_attention_layernorm): MistralRMSNorm()\n",
              "          )\n",
              "        )\n",
              "        (norm): MistralRMSNorm()\n",
              "      )\n",
              "      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save the fine-tuned model\n",
        "\n",
        "trainer.model.save_pretrained(new_model)\n",
        "wandb.finish()\n",
        "model.config.use_cache = True\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b80737a8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-14T00:38:04.861463Z",
          "iopub.status.busy": "2024-03-14T00:38:04.860594Z",
          "iopub.status.idle": "2024-03-14T00:38:04.866294Z",
          "shell.execute_reply": "2024-03-14T00:38:04.865440Z"
        },
        "papermill": {
          "duration": 0.022987,
          "end_time": "2024-03-14T00:38:04.868298",
          "exception": false,
          "start_time": "2024-03-14T00:38:04.845311",
          "status": "completed"
        },
        "tags": [],
        "id": "b80737a8",
        "outputId": "a9ba0fc6-58ef-4373-f15c-39eb25502d75"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'trainer.model.push_to_hub(\"username/directoryname\")'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Push the model to Huggingface\n",
        "\n",
        "trainer.model.push_to_hub(\"username/directoryname\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "979f20fa",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-14T00:38:04.898617Z",
          "iopub.status.busy": "2024-03-14T00:38:04.897992Z",
          "iopub.status.idle": "2024-03-14T00:38:13.675487Z",
          "shell.execute_reply": "2024-03-14T00:38:13.674654Z"
        },
        "papermill": {
          "duration": 8.795213,
          "end_time": "2024-03-14T00:38:13.677711",
          "exception": false,
          "start_time": "2024-03-14T00:38:04.882498",
          "status": "completed"
        },
        "tags": [],
        "id": "979f20fa",
        "outputId": "b83d8487-e6d2-4e99-ceb7-fa9cbe21cfac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The model 'PeftModel' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        }
      ],
      "source": [
        "# Testing the fine-tuned model on an abstract input that is out of training data\n",
        "\n",
        "prompt = \"The recent GPT-4 has demonstrated extraordinary multi-modal abilities, such as directly generating websites from handwritten text and identifying humorous elements within images. These features are rarely observed in previous vision-language models. However, the technical details behind GPT-4 continue to remain undisclosed. We believe that the enhanced multi-modal generation capabilities of GPT-4 stem from the utilization of sophisticated large language models (LLM). To examine this phenomenon, we present MiniGPT-4, which aligns a frozen visual encoder with a frozen advanced LLM, Vicuna, using one projection layer. Our work, for the first time, uncovers that properly aligning the visual features with an advanced large language model can possess numerous advanced multi-modal abilities demonstrated by GPT-4, such as detailed image description generation and website creation from hand-drawn drafts. Furthermore, we also observe other emerging capabilities in MiniGPT-4, including writing stories and poems inspired by given images, teaching users how to cook based on food photos, and so on. In our experiment, we found that the model trained on short image caption pairs could produce unnatural language outputs (e.g., repetition and fragmentation). To address this problem, we curate a detailed image description dataset in the second stage to finetune the model, which consequently improves the model's generation reliability and overall usability.\"\n",
        "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=400)\n",
        "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c0808a1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-14T00:38:13.708660Z",
          "iopub.status.busy": "2024-03-14T00:38:13.708033Z",
          "iopub.status.idle": "2024-03-14T00:38:13.714206Z",
          "shell.execute_reply": "2024-03-14T00:38:13.713143Z"
        },
        "papermill": {
          "duration": 0.02408,
          "end_time": "2024-03-14T00:38:13.716328",
          "exception": false,
          "start_time": "2024-03-14T00:38:13.692248",
          "status": "completed"
        },
        "tags": [],
        "id": "1c0808a1",
        "outputId": "56beb675-a1f7-441a-ea38-38cd0cea5061"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'generated_text': \"<s>[INST] The recent GPT-4 has demonstrated extraordinary multi-modal abilities, such as directly generating websites from handwritten text and identifying humorous elements within images. These features are rarely observed in previous vision-language models. However, the technical details behind GPT-4 continue to remain undisclosed. We believe that the enhanced multi-modal generation capabilities of GPT-4 stem from the utilization of sophisticated large language models (LLM). To examine this phenomenon, we present MiniGPT-4, which aligns a frozen visual encoder with a frozen advanced LLM, Vicuna, using one projection layer. Our work, for the first time, uncovers that properly aligning the visual features with an advanced large language model can possess numerous advanced multi-modal abilities demonstrated by GPT-4, such as detailed image description generation and website creation from hand-drawn drafts. Furthermore, we also observe other emerging capabilities in MiniGPT-4, including writing stories and poems inspired by given images, teaching users how to cook based on food photos, and so on. In our experiment, we found that the model trained on short image caption pairs could produce unnatural language outputs (e.g., repetition and fragmentation). To address this problem, we curate a detailed image description dataset in the second stage to finetune the model, which consequently improves the model's generation reliability and overall usability. [/INST] minigpt-4: a simple yet powerful multi-modal model with advanced capabilities 1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0 9.0 10.0 11.0 12.0 13.0 14.0 15.0 16.0 17.0 18.0\"}]\n"
          ]
        }
      ],
      "source": [
        "# Seeing the generated title\n",
        "\n",
        "print(result)"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 4456307,
          "sourceId": 7645276,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4518446,
          "sourceId": 7732411,
          "sourceType": "datasetVersion"
        },
        {
          "modelInstanceId": 3899,
          "sourceId": 5111,
          "sourceType": "modelInstanceVersion"
        }
      ],
      "dockerImageVersionId": 30665,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 31353.84092,
      "end_time": "2024-03-14T00:38:16.646917",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-03-13T15:55:42.805997",
      "version": "2.5.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}